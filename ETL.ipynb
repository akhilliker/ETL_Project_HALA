{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sqlalchemy\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull first csv into dataframe\n",
    "min_wage_file = \"Raw_Data/Minimum_Wage_Data.csv\"\n",
    "min_wage_df = pd.read_csv(min_wage_file, encoding = \"utf-8\")\n",
    "min_wage_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove years prior to 2010\n",
    "min_year_df = min_wage_df.loc[(min_wage_df['Year'] == 2010) |\n",
    "                          (min_wage_df['Year'] == 2011) |\n",
    "                          (min_wage_df['Year'] == 2012) |\n",
    "                          (min_wage_df['Year'] == 2013) |\n",
    "                          (min_wage_df['Year'] == 2014) |\n",
    "                          (min_wage_df['Year'] == 2015) |\n",
    "                          (min_wage_df['Year'] == 2016)]\n",
    "\n",
    "# alternative:\n",
    "# min_wage_df2 = min_wage_df[(min_wage_df[‘Year’] > 2009)]\n",
    "# min_wage_df2.head()\n",
    "\n",
    "min_year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove extraneous columns\n",
    "min_wage_df2 = min_year_df.drop(['Footnote', 'Table_Data', 'High.2018', 'Low.2018', 'CPI.Average'], axis =1)\n",
    "min_wage_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make column names lower-case\n",
    "min_wage_df2.columns = [\"year\",\"state\",\"high_value\",\"low_value\"]\n",
    "min_wage_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pull second csv into dataframe\n",
    "pub_assistance_file = \"Raw_Data/sub-est2016_all.csv\"\n",
    "pub_assistance_df = pd.read_csv(pub_assistance_file, encoding='utf-8')\n",
    "pub_assistance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be more readable\n",
    "pub_assistance_df.columns = [\"geographic_summary_level\",\"state_FIPS_code\", \"county_FIPS_code\", \"place_FIPS_code\", \"minor_civil_div_FIPS_code\", \"consolidated_city_FIPS_code\", \"primitive_geography_flag\", \"functional_status_code\",\"city\", \"state\", \"census_pop_2010\", \n",
    "                             \"est_base_2010\", \"est_pop_2010\", \"est_pop_2011\", \"est_pop_2012\", \"est_pop_2013\", \"est_pop_2014\", \"est_pop_2015\", \"est_pop_2016\"]\n",
    "\n",
    "pub_assistance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dictionary to replace SUMLEV column numbers with their description\n",
    "SUMLEV_dict = {\"geographic_summary_level\": [40,50,61,71,157,162,170,172],\n",
    "               \"geographic_level\": [\"State\", \"County\", \"Minor Civil Division\", \"Minor Civil Division place part\",\n",
    "                                    \"County place part\", \"Incorporated place\", \"Consolidated city\",\n",
    "                                    \"Consolidated city -- place within consolidated city\"]}\n",
    "\n",
    "SUMLEV_df = pd.DataFrame(SUMLEV_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dictionary with dataframe as new column\n",
    "new_pub_assist_df = pub_assistance_df.merge(SUMLEV_df, on='geographic_summary_level', how='left')\n",
    "new_pub_assist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out state entries\n",
    "state_pub_assist_df = new_pub_assist_df[(new_pub_assist_df['geographic_summary_level'] == 40)]\n",
    "state_pub_assist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop unneeded columns\n",
    "state_pub_assist_df2 = state_pub_assist_df.drop([\"census_pop_2010\", \"est_base_2010\", \"geographic_summary_level\",\"state_FIPS_code\", \"county_FIPS_code\", \"place_FIPS_code\", \"minor_civil_div_FIPS_code\", \n",
    "                                                 \"consolidated_city_FIPS_code\", \"primitive_geography_flag\", \"functional_status_code\", \"city\", \"geographic_level\"], axis=1)\n",
    "state_pub_assist_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rename year columns\n",
    "state_pub_assist_df2.columns = ['state', '2010', '2011', '2012', '2013', '2014', '2015', '2016']\n",
    "state_pub_assist_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# melt data from wide to long dataset\n",
    "something_new_df = pd.melt(state_pub_assist_df2, id_vars=['state'], value_vars=['2010', '2011', '2012', '2013', '2014', '2015', '2016'])\n",
    "something_new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rename columns\n",
    "something_new_df.columns = ['state', 'year', 'est_population']\n",
    "something_new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "something_new_df[\"WIC_usage\"] = 'NaN'\n",
    "something_new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rds_connection_string = \"root:<password>@127.0.0.1/demographics_db\"\n",
    "engine = create_engine(f'mysql://{rds_connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm tables\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "something_new_df.to_sql(name='pub_assist', con=engine, if_exists='append', index=True)\n",
    "min_wage_df2.to_sql(name='min_wage', con=engine, if_exists='append', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
